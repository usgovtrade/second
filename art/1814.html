<!DOCTYPE html><html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'><script async src='https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8422244967817077' crossorigin=anonymous'></script><link rel='stylesheet' href='/class.css'><script src='/script.js'></script></head><body><div class='topnav'></div><div class='list'><Br/><a href='1815.html'>Dumpster fire inte</a><Br/><a href='1816.html'>Cheap Flight and t</a><Br/><a href='1817.html'>Transferable Life-</a><Br/><a href='1818.html'>Collections and Me</a><Br/><a href='1819.html'>Car Insurance: AAA</a><Br/><a href='1820.html'>Sport Cars, On and</a><Br/><a href='1821.html'>Election Erection </a><Br/><a href='1822.html'>Life Pro Tips</a><Br/><a href='1823.html'>Reddit Memes</a><Br/><a href='1824.html'>Ductile Disfunctio</a></div><div class='stats'><div class='logodiv'><a href='/'><img class='logoimg' src='/img/elephant.svg' /></a></div> <Br/><a href='1813.html'>Travel Agent Fare </a><Br/><a href='1812.html'>Involuntary Drug T</a><Br/><a href='1811.html'>Secret Shopper, An</a><Br/><a href='1810.html'>Job Search, Dice, </a><Br/><a href='1809.html'>Recruiting, Placem</a><Br/><a href='1808.html'>Checking, Credit R</a><Br/><a href='1807.html'>Sustainability, Of</a><Br/><a href='1806.html'>Insane verticross </a><Br/><a href='1805.html'>15 Emerging Techno</a><Br/><a href='1804.html'>You’re stuck in my</a></div><div class='nav'><a href='1813.html'> << </a>&nbsp;&nbsp;&nbsp;&nbsp;<a href='1815.html'> >> </a></div><div class='article'>AI and Neural-Net generated portraits which were of superior quality. The CNN-based portrait generation could potentially be utilized as a tool to assess facial expression and could be used for emotional expression in video games, movie and cartoon movies.

I. Kotsia, A. Agavni, C. Koumparopoulos, P. Kanaris, and V. Ventriglia, “Learning to generate novel portraits from small image patches using an attention-based convolutional neural network,” in *Biomedical Imaging: Nano to Macro (IMIB), 2017 IEEE International Symposium on*.1em plus 0.5em minus 0.4emIEEE, 2017, pp. 1–6.

B. Gygli, G. Pellegrini, M. Piantanida, and V. Lepetit, “Natural face attributes in the wild: a large-scale image database for recognition, generation, and analysis,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2016.

T. D. Nguyen, T. Tran, A. Lebedev, and T. Pitie, “Face2face: Portrait Generation with Conditional GAN,” in *Advances in Neural Information Processing Systems*, 2017, pp. 4632–4640.

M. Zhao, Z. Lu, M. Kiskinova, L. Wan, and C. Gulcehre, “Identity-adaptive generative adversarial networks,” *arXiv preprint arXiv:1611.07100*, 2016.

T. J. O’Donnel, “Unsupervised learning and generative models: A review of techniques and applications,” *Neural Computation*, vol. 26, no. 10, pp. 2406–2440, 2014.

A. Radford, L. Metz, and S. Chintala, “Unsupervised representation learning with deep convolutional generative adversarial networks,” in *Advances in neural information processing systems*, 2015, pp. 1–9.

K. Sohn, J. Paisley, and M. Hebert, “Unpaired image-to-image translation networks,” in *International Conference on Learning Representations (ICLR)*, 2017.

I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in *Advances in neural information processing systems*, 2014, pp. 2672–2680.

Z. Huang, K. Zhang, J. Wang, H. Li, Z. Li, L. Ying, and M. Long, “Adequacy: Towards photo-realistic face image synthesis with identity preserved,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2015, pp. 1835–1842.

K. Isola, J. Yap, and A. Zisserman, “A multivariate lstm model for image generation,” in *Proceedings of the IEEE conference on computer vision and pattern recognition*, 2016, pp. 1377–1385.

L. Maal[ø]{}e, D. Arslan, E. Shechtman, and N. Ballas, “Voxelmorph: Facial animation from multimodal deep volumetric representations,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2017, pp. 3450–3458.

K. Uchida, H. Kameoka, and H. Shinoda, “Fully automatic portrait rendering from monocular images,” in *2012 IEEE Conference on Computer Vision and Pattern Recognition*, July 2012, pp. 2221–2229.

S. Fidler and R. Timofte, “Face swapping with cycle-consistent adversarial networks,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2018, pp. 1085–1094.

M. Hu, H. Wang, and W. Wu, “Disentangled face image synthesis with adversarial variational auto-encoders,” in *Proceedings of the European Conference on Computer Vision (ECCV)*, 2018, pp. 809–827.

B. Bhattacharjee, M. Munaf, and K. Bhargava, “Generative modeling of face attributes and expressions,” in *Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on*, vol. 2, june 2009.

D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” *arXiv preprint arXiv:1412.6980*, 2014.

T. Wen, B. Huang, Y. Zhang, C. Chen, and D. Tao, “Deep cross-domain features learning for face photo-ageing synthesis,” *arXiv preprint arXiv:1803.09563*, 2018.

C. Li, Z. Lai, W. Yan, X. Wang, and X. Lu, “Neural facial reenactment,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2017, pp. 4344–4353.

I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in *Advances in neural information processing systems*, 2014, pp. 2672–2680.

K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in *Proceedings of the IEEE conference on computer vision and pattern recognition*, 2016, pp. 770–778.

I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” *arXiv preprint arXiv:1406.2661*, 2014.

S. Mittal and N. Boult, “Generating synthetic traffic sign images using a deep generative adversarial network,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2018, pp. 8288–8297.

K. Uchida and H. Shinoda, “Automatic synthetic image generation using generative adversarial network: A review,“ in *Machine Vision and Applications*, vol. 31, no. 1, pp. 59–71, 2020.

D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” *CoRR, abs/1412.6980*, 2014. \[Online\]. Available: <http://arxiv.org/abs/1412.6980>

R. Mohan, M. Mathieu, R. Ganguli, and D. Rumelhart, “Generating faces from visual features via deep conditional probability,” in *Advances in neural information processing systems*, 2015, pp. 1486–1495.

M. Radford, S. Chintala, L. Metz, and I. Sutskever, “Unsupervised representation learning with deep convolutional generative adversarial networks,” *arXiv preprint arXiv:1511.06434*, 2015.

T. Yeh, Y. Liu, R. Chellappa, J. Kautz, and D. Magee, “Dark web.” (accessed 04.05.2020)

F. M. Khan, N. A. Shah, and S. Maharjan, “Deep image enhancement network: Artistic image enhancement using convolutional neural networks,” in *International Symposium on Circuits and Systems (ISCAS)*, 2018.

S. H. Tawfik, J. M. Buhmann, J. Chen, S. Mallick, and K. Rudd, “Unseen image generation using generative adversarial networks (gan),” in *Advances in neural information processing systems*, 2017, pp. 1281–1290.

D. Odena, C. Olah, and J. Shlens, “Conditional image synthesis with auxiliary classifier gans,” in *Advances in neural information processing systems*, 2016, pp. 742–750.

H. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, “Semantic image synthesis</div></body></html><!-- 2022-06-12 21:03:33 